{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'eduthie-sagemaker-1'\n",
    "prefix = 'gluon_recommender'\n",
    "\n",
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, ndarray\n",
    "from mxnet.metric import MSE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "import boto3\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2018-06-04-08-35-45-986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................\n",
      "\u001b[31m2018-06-04 08:42:13,336 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:13,337 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:13,710 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:15,171 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'available_cpus': 64, '_scheduler_ip': '10.32.0.4', 'hyperparameters': {'sagemaker_enable_cloudwatch_metrics': False, 'sagemaker_program': 'recommender.py', 'sagemaker_submit_directory': 's3://sagemaker-eu-west-1-987551451182/sagemaker-mxnet-2018-06-04-08-35-45-986/source/sourcedir.tar.gz', 'sagemaker_region': 'eu-west-1', 'num_embeddings': 512, 'sagemaker_container_log_level': 20, 'lr': 0.02, 'wd': 0.0, 'opt': 'sgd', 'sagemaker_job_name': 'sagemaker-mxnet-2018-06-04-08-35-45-986', 'epochs': 10, 'momentum': 0.9}, '_scheduler_host': 'algo-1', 'output_dir': '/opt/ml/output', 'user_script_name': 'recommender.py', 'user_script_archive': 's3://sagemaker-eu-west-1-987551451182/sagemaker-mxnet-2018-06-04-08-35-45-986/source/sourcedir.tar.gz', 'code_dir': '/opt/ml/code', 'channels': {'train': {'S3DistributionType': 'FullyReplicated', 'RecordWrapperType': 'None', 'TrainingInputMode': 'File'}}, 'model_dir': '/opt/ml/model', 'job_name': 'sagemaker-mxnet-2018-06-04-08-35-45-986', '_ps_port': 8000, 'base_dir': '/opt/ml', 'channel_dirs': {'train': '/opt/ml/input/data/train'}, 'hosts': ['algo-1'], 'resource_config': {'network_interface_name': 'ethwe', 'hosts': ['algo-1'], 'current_host': 'algo-1'}, 'sagemaker_region': 'eu-west-1', 'available_gpus': 16, 'input_config_dir': '/opt/ml/input/config', 'container_log_level': 20, '_ps_verbose': 0, 'current_host': 'algo-1', 'input_dir': '/opt/ml/input', 'output_data_dir': '/opt/ml/output/data/', 'user_requirements_file': None, 'enable_cloudwatch_metrics': False}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-eu-west-1-987551451182/sagemaker-mxnet-2018-06-04-08-35-45-986/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:15,298 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:15,397 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-eu-west-1-987551451182.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:15,442 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (2): sagemaker-eu-west-1-987551451182.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:15,456 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-eu-west-1-987551451182.s3.eu-west-1.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:15,501 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (2): sagemaker-eu-west-1-987551451182.s3.eu-west-1.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-06-04 08:42:15,693 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31mCollecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/c1/43966a4ce89d0c64111f46c6364ed57d6d87e6fab7d685dca06197a19cf7/pandas-0.23.0-cp35-cp35m-manylinux1_x86_64.whl (11.6MB)\u001b[0m\n",
      "\u001b[31mCollecting pytz>=2011k (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/83/15f7833b70d3e067ca91467ca245bae0f6fe56ddc7451aa0dc5606b120f2/pytz-2018.4-py2.py3-none-any.whl (510kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (1.13.3)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (2.7.3)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\u001b[0m\n",
      "\u001b[31mInstalling collected packages: pytz, pandas\u001b[0m\n",
      "\u001b[31mSuccessfully installed pandas-0.23.0 pytz-2018.4\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet_container/train.py:178: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  train_args = inspect.getargspec(user_module.train)\u001b[0m\n",
      "\u001b[31mb'Skipping line 92523: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 343254: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 524626: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 623024: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 977412: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 1496867: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 1711638: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 1787213: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 2395306: expected 15 fields, saw 22\\n'\u001b[0m\n",
      "\u001b[31mb'Skipping line 2527690: expected 15 fields, saw 22\\n'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py:630: DeprecationWarning: generator 'multi_stream_iter' raised StopIteration\n",
      "  for idx, event in sagemaker.logs.multi_stream_iter(client, log_group, stream_names, positions):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mepoch: 0\u001b[0m\n",
      "\u001b[31mEPOCH 0: MSE ON TRAINING and TEST: 0.9683504440737865. 1.3518057554076717\u001b[0m\n",
      "\u001b[31mepoch: 1\u001b[0m\n",
      "\u001b[31mEPOCH 1: MSE ON TRAINING and TEST: 0.8440807554593421. 1.2407326508173242\u001b[0m\n",
      "\u001b[31mepoch: 2\u001b[0m\n",
      "\u001b[31mEPOCH 2: MSE ON TRAINING and TEST: 0.79589849029699. 1.205945230196384\u001b[0m\n",
      "\u001b[31mepoch: 3\u001b[0m\n",
      "\u001b[31mEPOCH 3: MSE ON TRAINING and TEST: 0.8308787389937806. 1.2394235321366256\u001b[0m\n",
      "\u001b[31mepoch: 4\u001b[0m\n",
      "\u001b[31mEPOCH 7: MSE ON TRAINING and TEST: 0.6722131938437601. 1.219422062555224\u001b[0m\n",
      "\u001b[31mepoch: 8\u001b[0m\n",
      "\u001b[31mEPOCH 8: MSE ON TRAINING and TEST: 0.5154444976276445. 1.2505068283702248\u001b[0m\n",
      "\u001b[31mepoch: 9\u001b[0m\n",
      "\u001b[31mEPOCH 9: MSE ON TRAINING and TEST: 0.3398741641003822. 1.2781291879297254\u001b[0m\n",
      "\u001b[31mend of training\u001b[0m\n",
      "===== Job Complete =====\n",
      "Billable seconds: 8941\n"
     ]
    }
   ],
   "source": [
    "opt = 'sgd'\n",
    "lr = 0.02\n",
    "momentum = 0.9\n",
    "wd = 0.\n",
    "\n",
    "m = MXNet('recommender.py', \n",
    "          py_version='py3',\n",
    "          role=role, \n",
    "          train_instance_count=10, \n",
    "          train_instance_type=\"ml.p2.16xlarge\",\n",
    "          output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "          hyperparameters={'num_embeddings': 512, \n",
    "                           'opt': opt, \n",
    "                           'lr': lr, \n",
    "                           'momentum': momentum, \n",
    "                           'wd': wd,\n",
    "                           'epochs': 10})\n",
    "\n",
    "m.fit({'train': 's3://{}/{}/train/'.format(bucket, prefix)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate total cost of training\n",
    "\n",
    "The cost of training on such a large instance with 16 GPUs is relatively expensive at 21.773 euros per hour. Fortunately it is charged by the second. Here we calculate the total price.\n",
    "\n",
    "There is a lot more that can be done to optimise training speed and hence cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.07566472222222\n"
     ]
    }
   ],
   "source": [
    "price_per_second = 21.773/(60*60)\n",
    "total_price = 8941*price_per_second\n",
    "print(total_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host\n",
    "\n",
    "Now that we've trained our model, deploying it to a real-time, production endpoint is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-mxnet-2018-06-04-08-35-45-986\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-mxnet-2018-06-04-08-35-45-986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = m.deploy(initial_instance_count=1, \n",
    "                     instance_type='ml.m4.xlarge')\n",
    "predictor.serializer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an endpoint, let's test it out. We'll predict user #6's ratings for the top and bottom ASINs from our local model.\n",
    "\n",
    "This could be done by sending HTTP POST requests from a separate web service, but to keep things easy, we'll just use the .predict() method from the SageMaker Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"\". See https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-mxnet-2018-06-04-08-35-45-986 in account 987551451182 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-df2feb23fe3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m predictor.predict(json.dumps({'customer_id': '6', \n\u001b[0;32m----> 2\u001b[0;31m                               'product_id': ['B00KH1O9HW', 'B00M5KODWO']}))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mrequest_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accept'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mresponse_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    313\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"\". See https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-mxnet-2018-06-04-08-35-45-986 in account 987551451182 for more information."
     ]
    }
   ],
   "source": [
    "predictor.predict(json.dumps({'customer_id': '6', \n",
    "                              'product_id': ['B00KH1O9HW', 'B00M5KODWO']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, some of our predictions are actually greater than 5, which is to be expected as we didn't do anything special to account for ratings being capped at that value. Since we are only looking to ranking by predicted rating, this won't create problems for our specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Let's start by calculating a naive baseline to approximate how well our model is doing.  The simplest estimate would be to assume every user item rating is just the average rating over all ratings.\n",
    "\n",
    "*Note, we could do better by using each individual video's average, however, in this case it doesn't really matter as the same conclusions would hold.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Naive MSE:', np.mean((test_df['star_rating'] - np.mean(train_df['star_rating'])) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll calculate predictions for our test dataset.\n",
    "\n",
    "*Note, this will align closely to our CloudWatch output above, but may differ slightly due to skipping partial mini-batches in our eval_net function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for array in np.array_split(test_df[['customer_id', 'product_id']].values, 40):\n",
    "    test_preds += predictor.predict(json.dumps({'customer_id': array[:, 0].tolist(), \n",
    "                                                'product_id': array[:, 1].tolist()}))\n",
    "\n",
    "test_preds = np.array(test_preds)\n",
    "print('MSE:', np.mean((test_df['star_rating'] - test_preds) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our neural network and embedding model produces substantially better results (~1.27 vs 1.65 on mean square error).\n",
    "\n",
    "For recommender systems, subjective accuracy also matters.  Let's get some recommendations for a random user to see if they make intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df[reduced_df['user'] == 6].sort_values(['star_rating', 'item'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, user #6 seems to like sprawling dramamtic television series and sci-fi, but they dislike silly comedies.\n",
    "\n",
    "Now we'll loop through and predict user #6's ratings for every common video in the catalog, to see which ones we'd recommend and which ones we wouldn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for array in np.array_split(product_index['product_id'].values, 40):\n",
    "    predictions += predictor.predict(json.dumps({'customer_id': customer_index[customer_index['user'] == 6]['customer_id'].values.tolist() * array.shape[0], \n",
    "                                                 'product_id': array.tolist()}))\n",
    "\n",
    "predictions = pd.DataFrame({'product_id': product_index['product_id'],\n",
    "                            'prediction': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = reduced_df.groupby('product_id')['product_title'].last().reset_index()\n",
    "predictions_titles = predictions.merge(titles)\n",
    "predictions_titles.sort_values(['prediction', 'product_id'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, our predicted highly rated shows have some well-reviewed TV dramas and some sci-fi. Meanwhile, our bottom rated shows include goofball comedies.\n",
    "\n",
    "Note, because of random initialization in the weights, results on subsequent runs may differ slightly.\n",
    "\n",
    "Let's confirm that we no longer have almost perfect correlation in recommendations with user #7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_user7 = []\n",
    "for array in np.array_split(product_index['product_id'].values, 40):\n",
    "    predictions_user7 += predictor.predict(json.dumps({'customer_id': customer_index[customer_index['user'] == 7]['customer_id'].values.tolist() * array.shape[0], \n",
    "                                                       'product_id': array.tolist()}))\n",
    "plt.scatter(predictions['prediction'], np.array(predictions_user7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrap-up\n",
    "\n",
    "In this example, we developed a deep learning model to predict customer ratings.  This could serve as the foundation of a recommender system in a variety of use cases.  However, there are many ways in which it could be improved.  For example we did very little with:\n",
    "- hyperparameter tuning\n",
    "- controlling for overfitting (early stopping, dropout, etc.)\n",
    "- testing whether binarizing our target variable would improve results\n",
    "- including other information sources (video genres, historical ratings, time of review)\n",
    "- adjusting our threshold for user and item inclusion \n",
    "\n",
    "In addition to improving the model, we could improve the engineering by:\n",
    "- Setting the context and key value store up for distributed training\n",
    "- Fine tuning our data ingestion (e.g. num_workers on our data iterators) to ensure we're fully utilizing our GPU\n",
    "- Thinking about how pre-processing would need to change as datasets scale beyond a single machine\n",
    "\n",
    "Beyond that, recommenders are a very active area of research and techniques from active learning, reinforcement learning, segmentation, ensembling, and more should be investigated to deliver well-rounded recommendations.\n",
    "\n",
    "### Clean-up (optional)\n",
    "\n",
    "Let's finish by deleting our endpoint to avoid stray hosting charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
